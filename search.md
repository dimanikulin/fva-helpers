# 📱What You’ll Learn

- How to search by date on iPhone and Android
- How to filter photos by location
- A few extra tricks using albums and maps
- How search in media uses metadata: dates, people, locations, objects.

## ✅Step-by-Step: iPhone (Photos App)

1. Open the Photos app
2. Tap the “Photos” icon on your home screen.

3. Tap "Search" at the bottom
4. You’ll see suggestions like People, Places, and Categories.

5. Type a date or location
6. Try typing “January 2023” or “Paris”.

### 📌Pro tip: Use full months (“March”) instead of numbers (“03”).

1. Scroll down to “Places”
2. You’ll see a map showing where photos were taken. Tap any city or pin.

3. Tap into Albums > Places
4. If you want a broader view, go to Albums → People & Places → Places.

## ✅Step-by-Step: Android (Google Photos)

1. Open Google Photos app
2. Make sure you're signed in to the right Google account.

3. Tap the Search bar at the top
4. Suggestions will appear, like Locations, Categories, and People.

5. Search by Month or Location
6. Try “June 2022” or “New York”.

## 📌Bonus: Try “sunset” or “beach” if you can’t remember the date.

1. Use the map view
2. Scroll down and tap the map under the “Places” section to browse by city or country.

### Bonus Tips
- Use the “Albums” tab if you’ve ever organized photos after a trip.
- Tap “Recents” if it was something you looked at recently.
- Check shared albums – sometimes your photos are in someone else’s shared space.

## How search in media uses metadata: dates, people, locations, objects.

Search in media — such as photos, videos, or audio — relies heavily on metadata, which is “data about data.” Metadata describes key attributes of the media file, enabling efficient organization, filtering, and retrieval. Here’s how different types of metadata are used in search:

### 🗓️ Dates

**What it means:** The date and time when a photo or video was taken or created (often from camera EXIF data or file properties).

**How it helps:**

- You can search for “photos from July 2022” or “videos from last weekend.”
- Systems can automatically sort media chronologically or generate timelines.
- Useful for detecting trends or changes over time (e.g., “compare photos from 2019 vs 2024”).

### 👥 People

**What it means:** Information about the individuals who appear in photos or videos, often extracted using face recognition.

**How it helps:**

- You can search by person name (“show all photos of Anna”).
- Helps group images by the same face across events or devices.
- Enables tagging and personalized collections (e.g., “My family album”).

### 📍Locations

**What it means:** GPS coordinates or named places embedded in media metadata (e.g., EXIF geotags or location tags).

**How it helps:**

- Enables geographic search (“videos shot in Paris”).
- Lets users view media on maps or organize by travel destinations.
- Supports contextual queries like “photos near the Eiffel Tower.”

### 🏷️Objects / Content

**What it means:** Detected visual elements — objects, scenes, activities — extracted via AI-based image or video recognition.

**How it helps:**

- Allows semantic searches: “photos with cats,” “videos of cars,” or “sunset on the beach.”
- Makes untagged media searchable without manual labeling.
- Enables content-based organization (e.g., grouping all food photos).

### 💡Combined Search Example

Modern media libraries (like Google Photos, Apple Photos, or AI-powered archives) combine these metadata types:

“Show photos of Alex at the beach in 2023”
→ Filter by person = Alex, object = beach, date = 2023, and possibly location = coastal region.
